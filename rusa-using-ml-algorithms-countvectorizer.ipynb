{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom nltk.stem import SnowballStemmer\nfrom nltk.corpus import stopwords\n%matplotlib inline\n\n#Results reporting Libraries\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report \n\n#Classifiers related libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Preparing Dataset","metadata":{}},{"cell_type":"code","source":"Dataset = pd.read_csv('../input/encoded-rusa/Cleaned_Encoded RUSA Dataset.csv')\n# Dataset.head()","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Dataset = Dataset.drop(['Unnamed: 0'],axis=1)\nDataset['Sentiment']=Dataset['Sentiment'].replace('positive',0)\nDataset['Sentiment']=Dataset['Sentiment'].replace('negative',1)\nDataset.head()","metadata":{"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Sentiment                                             Review  \\\n0          1   ab achanak khawaja saad rafique ko khiyaal aa...   \n1          1   adha drama to censor hi hojaye gaa , khaas to...   \n2          1   bekaar fuzool end !!!!! moti budhi laila jeet...   \n3          1            choor kasuri choor jhootay ka moo kaala   \n4          1   gali gali mein shor hai gaaanjaaaa shair chor...   \n\n                                      Cleaned_Review  \\\n0   ab achanak khawaja saad rafique ko khiyaal aa...   \n1   adha drama to censor hi hojaye gaa  khaas tor...   \n2   bekaar fuzool end  moti budhi laila jeet gaye...   \n3            choor kasuri choor jhootay ka moo kaala   \n4   gali gali mein shor hai gaaanjaaaa shair chor...   \n\n                                 Standardized_Review  \\\n0   ab achanak khawaja sad rafique ko khiyal agay...   \n1   adha drama to censor hi hojaye ga khas tor pe...   \n2   bekaar fuzool end moti budhi laila jeet gayee...   \n3                chor kasuri chor jhootay ka mu kala   \n4       gali gali main shor hai ganja shair chor hai   \n\n                                             Soundex  \\\n0   A100 A252 K200 S300 R120 K000 K400 A200 W000 ...   \n1   A300 D650 T000 C526 H000 H200 G000 K200 T600 ...   \n2   B260 F240 E530 M300 B300 L400 J300 G000 L400 ...   \n3                 C600 K260 C600 J300 K000 M000 K400   \n4       G400 G400 M500 S600 H000 G520 S600 C600 H000   \n\n                                      RefinedSoundex  \\\n0   A1 A383 K4 S6 R25 K K7 A4 W B P39 M I3 L8 P  ...   \n1   A6 D98 T C839 H H4 G K3 T9 P9 B386 S84 B193 S...   \n2   B39 F57 E86 M6 B6 L7 J6 G L7 D39 L938 K M38 K...   \n3                                C9 K39 C9 J6 K M K7   \n4                          G7 G7 M8 S9 H G84 S9 C9 H   \n\n                                         MetaSoundex  \\\n0   0100 0252 5000 4300 9120 5000 5400 0200 7000 ...   \n1   0300 3650 3000 4526 5000 5200 5000 5000 3600 ...   \n2   7260 7240 0530 6300 7300 8000 1300 5000 8000 ...   \n3                 5600 5600 5600 1300 5000 6000 5400   \n4       5400 5400 6000 5600 5000 5520 5600 5600 5000   \n\n                                        FuzzySoundex  \\\n0   A1000 A9570 K7000 S3000 R1700 K0000 K4000 A70...   \n1   A3000 D6500 T0000 S5960 H0000 H7000 G0000 K90...   \n2   B7600 F9400 E5300 M3000 B3000 L4000 J3000 G00...   \n3          C6000 K9600 C6000 J3000 K0000 M0000 K4000   \n4   G4000 G4000 M5000 S6000 H0000 G5700 S6000 C60...   \n\n                                                LEIN  \\\n0   A400 A525 K500 S100 R450 K000 K300 A500 W000 ...   \n1   A100 D320 T000 C253 H000 H500 G000 K500 T300 ...   \n2   B530 F530 E210 M100 B100 L300 J100 G000 L300 ...   \n3                 C300 K530 C300 J100 K000 M000 K300   \n4       G300 G300 M200 S300 H000 G250 S300 C300 H000   \n\n                                              NYSIIS  \\\n0   AB ACANAC CAJ SAD RAFAG C CAYAL AGAY W B PASA...   \n1   AD DRAN T CANSAR H HAJAY G C TAR PAR BASAD SA...   \n2   BACAR FASAL ED MAT BAD LAL JAT GY LAL DASR LA...   \n3                         CAR CASAR CAR JATY C M CAL   \n4                   GAL GAL MAN SAR H GANJ SAR CAR H   \n\n                                          Caverphone  \\\n0   AP11111111 AKNK111111 KWA1111111 ST11111111 R...   \n1   ATA1111111 TRMA111111 TA11111111 SNSA111111 A...   \n2   PKA1111111 FSA1111111 ANT1111111 MTA1111111 P...   \n3   KA11111111 KSRA111111 KA11111111 ATA1111111 K...   \n4   KLA1111111 KLA1111111 MN11111111 SA11111111 A...   \n\n                                              SoundD  \\\n0   1000 2520 2200 2300 6120 2000 2400 2000 0000 ...   \n1   3000 3650 3000 2526 0000 2000 2000 2200 3600 ...   \n2   1260 1240 5300 5300 1300 4400 2300 2000 4400 ...   \n3                 2600 2260 2600 2300 2000 5000 2400   \n4       2400 2400 5500 2600 0000 2520 2600 2600 0000   \n\n                                           Metaphone  \n0   AB AXNK KHWJ ST RFK K KHYL AKY W BH PXWR M IS...  \n1   ATH TRM T SNSR H HJY K KHS TR PR BSNT SNK BBR...  \n2   BKR FSL ENT MT BTH LL JT KY LL TSR LRKYN K MS...  \n3                               XR KSR XR JHT K M KL  \n4                          KL KL MN XR H KNJ XR XR H  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentiment</th>\n      <th>Review</th>\n      <th>Cleaned_Review</th>\n      <th>Standardized_Review</th>\n      <th>Soundex</th>\n      <th>RefinedSoundex</th>\n      <th>MetaSoundex</th>\n      <th>FuzzySoundex</th>\n      <th>LEIN</th>\n      <th>NYSIIS</th>\n      <th>Caverphone</th>\n      <th>SoundD</th>\n      <th>Metaphone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>ab achanak khawaja saad rafique ko khiyaal aa...</td>\n      <td>ab achanak khawaja saad rafique ko khiyaal aa...</td>\n      <td>ab achanak khawaja sad rafique ko khiyal agay...</td>\n      <td>A100 A252 K200 S300 R120 K000 K400 A200 W000 ...</td>\n      <td>A1 A383 K4 S6 R25 K K7 A4 W B P39 M I3 L8 P  ...</td>\n      <td>0100 0252 5000 4300 9120 5000 5400 0200 7000 ...</td>\n      <td>A1000 A9570 K7000 S3000 R1700 K0000 K4000 A70...</td>\n      <td>A400 A525 K500 S100 R450 K000 K300 A500 W000 ...</td>\n      <td>AB ACANAC CAJ SAD RAFAG C CAYAL AGAY W B PASA...</td>\n      <td>AP11111111 AKNK111111 KWA1111111 ST11111111 R...</td>\n      <td>1000 2520 2200 2300 6120 2000 2400 2000 0000 ...</td>\n      <td>AB AXNK KHWJ ST RFK K KHYL AKY W BH PXWR M IS...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>adha drama to censor hi hojaye gaa , khaas to...</td>\n      <td>adha drama to censor hi hojaye gaa  khaas tor...</td>\n      <td>adha drama to censor hi hojaye ga khas tor pe...</td>\n      <td>A300 D650 T000 C526 H000 H200 G000 K200 T600 ...</td>\n      <td>A6 D98 T C839 H H4 G K3 T9 P9 B386 S84 B193 S...</td>\n      <td>0300 3650 3000 4526 5000 5200 5000 5000 3600 ...</td>\n      <td>A3000 D6500 T0000 S5960 H0000 H7000 G0000 K90...</td>\n      <td>A100 D320 T000 C253 H000 H500 G000 K500 T300 ...</td>\n      <td>AD DRAN T CANSAR H HAJAY G C TAR PAR BASAD SA...</td>\n      <td>ATA1111111 TRMA111111 TA11111111 SNSA111111 A...</td>\n      <td>3000 3650 3000 2526 0000 2000 2000 2200 3600 ...</td>\n      <td>ATH TRM T SNSR H HJY K KHS TR PR BSNT SNK BBR...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>bekaar fuzool end !!!!! moti budhi laila jeet...</td>\n      <td>bekaar fuzool end  moti budhi laila jeet gaye...</td>\n      <td>bekaar fuzool end moti budhi laila jeet gayee...</td>\n      <td>B260 F240 E530 M300 B300 L400 J300 G000 L400 ...</td>\n      <td>B39 F57 E86 M6 B6 L7 J6 G L7 D39 L938 K M38 K...</td>\n      <td>7260 7240 0530 6300 7300 8000 1300 5000 8000 ...</td>\n      <td>B7600 F9400 E5300 M3000 B3000 L4000 J3000 G00...</td>\n      <td>B530 F530 E210 M100 B100 L300 J100 G000 L300 ...</td>\n      <td>BACAR FASAL ED MAT BAD LAL JAT GY LAL DASR LA...</td>\n      <td>PKA1111111 FSA1111111 ANT1111111 MTA1111111 P...</td>\n      <td>1260 1240 5300 5300 1300 4400 2300 2000 4400 ...</td>\n      <td>BKR FSL ENT MT BTH LL JT KY LL TSR LRKYN K MS...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>choor kasuri choor jhootay ka moo kaala</td>\n      <td>choor kasuri choor jhootay ka moo kaala</td>\n      <td>chor kasuri chor jhootay ka mu kala</td>\n      <td>C600 K260 C600 J300 K000 M000 K400</td>\n      <td>C9 K39 C9 J6 K M K7</td>\n      <td>5600 5600 5600 1300 5000 6000 5400</td>\n      <td>C6000 K9600 C6000 J3000 K0000 M0000 K4000</td>\n      <td>C300 K530 C300 J100 K000 M000 K300</td>\n      <td>CAR CASAR CAR JATY C M CAL</td>\n      <td>KA11111111 KSRA111111 KA11111111 ATA1111111 K...</td>\n      <td>2600 2260 2600 2300 2000 5000 2400</td>\n      <td>XR KSR XR JHT K M KL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>gali gali mein shor hai gaaanjaaaa shair chor...</td>\n      <td>gali gali mein shor hai gaaanjaaaa shair chor...</td>\n      <td>gali gali main shor hai ganja shair chor hai</td>\n      <td>G400 G400 M500 S600 H000 G520 S600 C600 H000</td>\n      <td>G7 G7 M8 S9 H G84 S9 C9 H</td>\n      <td>5400 5400 6000 5600 5000 5520 5600 5600 5000</td>\n      <td>G4000 G4000 M5000 S6000 H0000 G5700 S6000 C60...</td>\n      <td>G300 G300 M200 S300 H000 G250 S300 C300 H000</td>\n      <td>GAL GAL MAN SAR H GANJ SAR CAR H</td>\n      <td>KLA1111111 KLA1111111 MN11111111 SA11111111 A...</td>\n      <td>2400 2400 5500 2600 0000 2520 2600 2600 0000</td>\n      <td>KL KL MN XR H KNJ XR XR H</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Code not needed to be changed","metadata":{}},{"cell_type":"code","source":"# Helper Functions\ndef train_classifier(clf, feature_train, labels_train):    \n    clf.fit(feature_train, labels_train)\ndef predict_labels(clf, features):\n    return (clf.predict(features))","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"svc = SVC(kernel='rbf', gamma=1.0)\nknc = KNeighborsClassifier(n_neighbors=5)\nmnb = MultinomialNB(alpha=0.2)\ndtc = DecisionTreeClassifier(min_samples_split=7, random_state=111)\nlrc = LogisticRegression(solver='liblinear', penalty='l1')\nrfc = RandomForestClassifier()\nabc = AdaBoostClassifier()\nbc = BaggingClassifier()\netc = ExtraTreesClassifier()","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"clfs = {'SVC' : svc,'KN' : knc, 'NB': mnb, 'DT': dtc, 'LR': lrc, 'RF': rfc, 'AdaBoost': abc, 'BgC': bc, 'ETC': etc}","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Un-Normalized Reviews","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['Cleaned_Review'])","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"features_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.591212\nPrecision: 0.543019\nRecall: 0.912492\nF1 score: 0.680861\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.599697\nPrecision: 0.759109\nRecall: 0.237793\nF1 score: 0.362144\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.780909\nPrecision: 0.802837\nRecall: 0.717819\nF1 score: 0.757951\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.695455\nPrecision: 0.677200\nRecall: 0.693088\nF1 score: 0.685052\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.800909\nPrecision: 0.794118\nRecall: 0.787571\nF1 score: 0.790831\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.765152\nPrecision: 0.750000\nRecall: 0.762841\nF1 score: 0.756366\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.698485\nPrecision: 0.737357\nRecall: 0.573240\nF1 score: 0.645023\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.717273\nPrecision: 0.704315\nRecall: 0.703868\nF1 score: 0.704091\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.786061\nPrecision: 0.769994\nRecall: 0.787571\nF1 score: 0.778683\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Standardized Reviews","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['Standardized_Review'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.587879\nPrecision: 0.539875\nRecall: 0.931516\nF1 score: 0.683574\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.616364\nPrecision: 0.777184\nRecall: 0.276474\nF1 score: 0.407858\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.788485\nPrecision: 0.799183\nRecall: 0.744451\nF1 score: 0.770847\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.698182\nPrecision: 0.683744\nRecall: 0.685479\nF1 score: 0.684611\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.803333\nPrecision: 0.797055\nRecall: 0.789474\nF1 score: 0.793246\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.771515\nPrecision: 0.746851\nRecall: 0.789474\nF1 score: 0.767571\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.718182\nPrecision: 0.746382\nRecall: 0.621433\nF1 score: 0.678201\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.739697\nPrecision: 0.731912\nRecall: 0.718453\nF1 score: 0.725120\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.796061\nPrecision: 0.777983\nRecall: 0.802156\nF1 score: 0.789884\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Soundex","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['Soundex'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.591212\nPrecision: 0.540254\nRecall: 0.970197\nF1 score: 0.694035\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.659394\nPrecision: 0.700620\nRecall: 0.501585\nF1 score: 0.584627\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.761212\nPrecision: 0.750159\nRecall: 0.750159\nF1 score: 0.750159\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.663333\nPrecision: 0.647843\nRecall: 0.647432\nF1 score: 0.647637\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.770303\nPrecision: 0.775017\nRecall: 0.731769\nF1 score: 0.752772\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.759394\nPrecision: 0.732897\nRecall: 0.781230\nF1 score: 0.756292\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.725455\nPrecision: 0.744000\nRecall: 0.648700\nF1 score: 0.693089\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.700606\nPrecision: 0.690615\nRecall: 0.676601\nF1 score: 0.683536\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.773636\nPrecision: 0.743545\nRecall: 0.803424\nF1 score: 0.772326\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### RefinedSoundex","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['RefinedSoundex'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.603939\nPrecision: 0.550186\nRecall: 0.938491\nF1 score: 0.693696\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.613333\nPrecision: 0.743922\nRecall: 0.291059\nF1 score: 0.418414\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.766667\nPrecision: 0.764590\nRecall: 0.739379\nF1 score: 0.751773\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.687879\nPrecision: 0.680290\nRecall: 0.654407\nF1 score: 0.667098\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.766970\nPrecision: 0.770053\nRecall: 0.730501\nF1 score: 0.749756\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.759091\nPrecision: 0.745295\nRecall: 0.753329\nF1 score: 0.749290\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.705455\nPrecision: 0.752715\nRecall: 0.571338\nF1 score: 0.649603\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.718182\nPrecision: 0.720218\nRecall: 0.670894\nF1 score: 0.694682\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.775455\nPrecision: 0.750299\nRecall: 0.794547\nF1 score: 0.771789\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### MetaSoundex","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['MetaSoundex'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.587879\nPrecision: 0.539043\nRecall: 0.949905\nF1 score: 0.687787\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.640606\nPrecision: 0.648443\nRecall: 0.541535\nF1 score: 0.590187\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.712121\nPrecision: 0.703969\nRecall: 0.686113\nF1 score: 0.694926\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.629091\nPrecision: 0.615890\nRecall: 0.594800\nF1 score: 0.605161\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.719697\nPrecision: 0.728933\nRecall: 0.658212\nF1 score: 0.691769\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.725152\nPrecision: 0.699881\nRecall: 0.743817\nF1 score: 0.721180\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.702424\nPrecision: 0.700878\nRecall: 0.658212\nF1 score: 0.678875\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.675758\nPrecision: 0.671168\nRecall: 0.630311\nF1 score: 0.650098\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.735758\nPrecision: 0.713766\nRecall: 0.746354\nF1 score: 0.729696\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### FuzzySoundex","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['FuzzySoundex'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.590606\nPrecision: 0.539845\nRecall: 0.970831\nF1 score: 0.693859\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.659394\nPrecision: 0.699208\nRecall: 0.504122\nF1 score: 0.585851\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.767879\nPrecision: 0.763141\nRecall: 0.745720\nF1 score: 0.754330\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.664545\nPrecision: 0.647985\nRecall: 0.652505\nF1 score: 0.650237\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.777576\nPrecision: 0.779324\nRecall: 0.745720\nF1 score: 0.762152\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.758788\nPrecision: 0.734817\nRecall: 0.774889\nF1 score: 0.754321\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.733636\nPrecision: 0.713065\nRecall: 0.740647\nF1 score: 0.726594\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.711212\nPrecision: 0.703922\nRecall: 0.682942\nF1 score: 0.693273\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.776364\nPrecision: 0.751348\nRecall: 0.795181\nF1 score: 0.772643\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### LEIN","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['LEIN'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.591212\nPrecision: 0.540254\nRecall: 0.970197\nF1 score: 0.694035\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.652727\nPrecision: 0.692927\nRecall: 0.490805\nF1 score: 0.574610\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.752727\nPrecision: 0.745960\nRecall: 0.731769\nF1 score: 0.738796\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.641818\nPrecision: 0.629849\nRecall: 0.607483\nF1 score: 0.618464\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.766061\nPrecision: 0.772512\nRecall: 0.723526\nF1 score: 0.747217\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.748182\nPrecision: 0.720449\nRecall: 0.772987\nF1 score: 0.745794\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.719394\nPrecision: 0.716567\nRecall: 0.682942\nF1 score: 0.699351\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.693030\nPrecision: 0.686262\nRecall: 0.658846\nF1 score: 0.672274\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.760909\nPrecision: 0.734245\nRecall: 0.783133\nF1 score: 0.757901\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### NYSIIS","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['NYSIIS'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.596970\nPrecision: 0.545122\nRecall: 0.946100\nF1 score: 0.691701\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.612727\nPrecision: 0.764602\nRecall: 0.273938\nF1 score: 0.403361\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.776364\nPrecision: 0.776898\nRecall: 0.746354\nF1 score: 0.761320\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.708485\nPrecision: 0.701904\nRecall: 0.677869\nF1 score: 0.689677\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.778485\nPrecision: 0.792127\nRecall: 0.727330\nF1 score: 0.758347\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.764242\nPrecision: 0.753973\nRecall: 0.752061\nF1 score: 0.753016\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.716061\nPrecision: 0.764901\nRecall: 0.585923\nF1 score: 0.663555\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.737273\nPrecision: 0.743151\nRecall: 0.688015\nF1 score: 0.714521\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.780000\nPrecision: 0.762492\nRecall: 0.783767\nF1 score: 0.772983\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Caverphone","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['Caverphone'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.592121\nPrecision: 0.540856\nRecall: 0.969562\nF1 score: 0.694369\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.642727\nPrecision: 0.689524\nRecall: 0.459100\nF1 score: 0.551199\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.756970\nPrecision: 0.741734\nRecall: 0.753963\nF1 score: 0.747799\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.660606\nPrecision: 0.645449\nRecall: 0.642993\nF1 score: 0.644219\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.767576\nPrecision: 0.775510\nRecall: 0.722892\nF1 score: 0.748277\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.752121\nPrecision: 0.734404\nRecall: 0.753963\nF1 score: 0.744055\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.727273\nPrecision: 0.731058\nRecall: 0.679138\nF1 score: 0.704142\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.687879\nPrecision: 0.681006\nRecall: 0.652505\nF1 score: 0.666451\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.771818\nPrecision: 0.748492\nRecall: 0.786937\nF1 score: 0.767233\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### SoundD","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['SoundD'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.585455\nPrecision: 0.538236\nRecall: 0.932784\nF1 score: 0.682599\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.602121\nPrecision: 0.612245\nRecall: 0.456563\nF1 score: 0.523066\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.715152\nPrecision: 0.706149\nRecall: 0.691820\nF1 score: 0.698911\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.623333\nPrecision: 0.610158\nRecall: 0.586557\nF1 score: 0.598125\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.716970\nPrecision: 0.740824\nRecall: 0.627140\nF1 score: 0.679258\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.705758\nPrecision: 0.686576\nRecall: 0.707039\nF1 score: 0.696657\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.688485\nPrecision: 0.704393\nRecall: 0.599873\nF1 score: 0.647945\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.666061\nPrecision: 0.669522\nRecall: 0.594800\nF1 score: 0.629953\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.725758\nPrecision: 0.710000\nRecall: 0.720355\nF1 score: 0.715140\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Metaphone","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer(input = 'english')\nfeatures = vectorizer.fit_transform(Dataset['Metaphone'])\n\nfeatures_train, features_test, labels_train, labels_test = train_test_split(\n    features, Dataset['Sentiment'], test_size=0.3, random_state=111)\n\nfor k,v in clfs.items():\n    train_classifier(v, features_train, labels_train)\n    pred = predict_labels(v,features_test)\n    print(\"Results by using\", k)\n    # accuracy: (tp + tn) / (p + n)\n    accuracy = accuracy_score(labels_test, pred)\n    print('Accuracy: %f' % accuracy)\n    # precision tp / (tp + fp)\n    precision = precision_score(labels_test, pred)\n    print('Precision: %f' % precision)\n    # recall: tp / (tp + fn)\n    recall = recall_score(labels_test, pred)\n    print('Recall: %f' % recall)\n    # f1: 2 tp / (2 tp + fp + fn)\n    f1 = f1_score(labels_test, pred)\n    print('F1 score: %f' % f1)\n    print(\"---------------------------------------------------------\")","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Results by using SVC\nAccuracy: 0.600606\nPrecision: 0.547246\nRecall: 0.951173\nF1 score: 0.694766\n---------------------------------------------------------\nResults by using KN\nAccuracy: 0.620606\nPrecision: 0.778731\nRecall: 0.287888\nF1 score: 0.420370\n---------------------------------------------------------\nResults by using NB\nAccuracy: 0.782424\nPrecision: 0.776206\nRecall: 0.765377\nF1 score: 0.770754\n---------------------------------------------------------\nResults by using DT\nAccuracy: 0.707273\nPrecision: 0.692502\nRecall: 0.696893\nF1 score: 0.694690\n---------------------------------------------------------\nResults by using LR\nAccuracy: 0.773939\nPrecision: 0.774257\nRecall: 0.743817\nF1 score: 0.758732\n---------------------------------------------------------\nResults by using RF\nAccuracy: 0.772727\nPrecision: 0.758923\nRecall: 0.768548\nF1 score: 0.763705\n---------------------------------------------------------\nResults by using AdaBoost\nAccuracy: 0.729091\nPrecision: 0.784821\nRecall: 0.596703\nF1 score: 0.677954\n---------------------------------------------------------\nResults by using BgC\nAccuracy: 0.735455\nPrecision: 0.744105\nRecall: 0.680406\nF1 score: 0.710831\n---------------------------------------------------------\nResults by using ETC\nAccuracy: 0.790303\nPrecision: 0.767049\nRecall: 0.805961\nF1 score: 0.786024\n---------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}